<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SMART: Scalable Multi-agent Real-time Motion Generation via Next-token Prediction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SMART: Scalable Multi-agent Real-time Motion Generation via Next-token Prediction</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SMART: Scalable Multi-agent Real-time Motion Generation via Next-token Prediction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Wei Wu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Xiaoxin Feng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Ziyan Gao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Yuheng Kan</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>SenseTime Research</span>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2405.15677"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.15677"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/regenmacher22/SMART"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="./static/sota_results/5e3eab58a6df9402_sim_sota.gif" alt="steve" width="200" height="200">
        </div>
        <div class="item item-chair-tp">
          <img src="./static/sota_results/68f9bdd777a8dcfe_sim_sota.gif" alt="chair-tp" width="200" height="200">
        </div>
        <div class="item item-shiba">
          <img src="./static/sota_results/366a9c2a6c8bc2ec_sim_sota.gif" alt="shiba" width="200" height="200">
        </div>
        <div class="item item-fullbody">
          <img src="./static/sota_results/550fb9aba453daca_sim_sota.gif" alt="fullbody" width="200" height="200">
        </div>
        <div class="item item-blueshirt">
          <img src="./static/sota_results/6350c7915446faa7_sim_sota.gif" alt="blueshirt" width="200" height="200">
        </div>
        <div class="item item-mask">
          <img src="./static/sota_results/bb3cc9253abc3352_sim_sota.gif" alt="mask" width="200" height="200">
        </div>
        <div class="item item-coffee">
          <img src="./static/sota_results/d401b4bec2f34e62_sim_sota.gif" alt="coffee" width="200" height="200">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Data-driven autonomous driving motion generation tasks are frequently impacted by the limitations of dataset size and the domain gap between datasets, which precludes their extensive application in real-world scenarios. To address this issue, we introduce SMART, a novel autonomous driving motion generation paradigm that models vectorized map and agent trajectory data into discrete sequence tokens. These tokens are then processed through a decoder-only transformer architecture to train for the next token prediction task across spatial-temporal series. This GPT-style method allows the model to learn the motion distribution in real driving scenarios. SMART achieves state-of-the-art performance across most of the metrics on the generative Sim Agents challenge, ranking 1st on the leaderboards of Waymo Open Motion Dataset (WOMD), demonstrating remarkable inference speed. Moreover, SMART represents the generative model in the autonomous driving motion domain, exhibiting zero-shot generalization capabilities: Using only the NuPlan dataset for training and WOMD for validation, SMART achieved a competitive score of 0.71 on the Sim Agents challenge. Lastly, we have collected over 1 billion motion tokens from multiple datasets, validating the model’s scalability. These results suggest that SMART has initially emulated two important properties: scalability and zero-shot generalization, and preliminarily meets the needs of large-scale real-time simulation applications. We have released all the code to promote the exploration of models for motion generation in the autonomous driving field.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video" style="max-width: 100%; overflow: hidden;">
          <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 100%; max-height: 300px;">
            <source src="./static/video/sota_result.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <!-- News section. -->
    <div class="columns is-centered has-text-left">
      <div class="column is-four-fifths">
        <span class="border border-white">
          <h2 class="title is-3 has-text-centered">News</h2>
          <ul>
            <!-- <li>[October 2020] code release on <a href='https://github.com/regenmacher22/SMART' target="_blank">github</a></li> -->
            <li>[TBA] code release</li>
            <li>[May 2024] paper released on <a href='https://arxiv.org/abs/2312.04535' target='_blank'>arxiv</a></li>
            <li>[May 2024] SMART win the Champion of <a href="https://waymo.com/open/challenges/2024/sim-agents/" target='_blank'>Waymo Sim Agents 2024 Benchmark</a></li>
          </ul>
        </span>
      </div>
    </div>
    <!--/ News section. -->

  </div>
</section>
</span>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Zero-shot Generalization. -->
      <div class="column">
        <div class="content" style="height: 100%;">
          <h2 class="title is-3">Zero-shot Generalization</h2>
          <p>
            In driving motion generation, we have focused on the model’s zero-shot generalizability across datasets. 
            SMART, trained solely on the NuPlan dataset, performed well on the WOMD test dataset, despite the non-overlapping
            map areas. The following videos show SMART's performance, with scenarios nearly absent in NuPlan, highlighting 
            its ability to generalize and perform in unseen conditions. This demonstrates SMART's robustness in generating 
            realistic and diverse motion patterns in novel situations.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline style="width: 100%; height: auto;">
            <source src="./static/video/nuplan2waymo.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Zero-shot Generalization. -->

      <!-- Scenario Generalization. -->
      <div class="column">
        <div class="content" style="height: 100%;">
          <h2 class="title is-3">Scenario Generalization</h2>
          <p>
            As a motion generation model, SMART is capable of generalizing log scenarios to produce a multitude of simulation 
            scenarios. The following videos demonstrate several examples of scenario generalization, 
            showcasing the versatility and robustness of SMART in creating diverse and realistic driving environments.
            These examples illustrate how SMART can effectively simulate various conditions and interactions,
            enhancing the scope and reliability of autonomous driving simulations.
          </p>
          <video id="matting-video" controls playsinline style="width: 100%; height: auto;">
            <source src="./static/video/scenario_generalization.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Scenario Generalization. -->
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{wu2024smart,
  title     = {SMART: Scalable Multi-agent Real-time Simulation via Next-token Prediction},
  author    = {Wu, Wei and Feng, Xiaoxin and Gao, Ziyan and Kan, Yuheng},
  journal   = {arXiv preprint arXiv:2405.15677},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is forked from the
            <a href="https://nerfies.github.io/">Nerfies website</a> and
            <a
              href="https://github.com/nerfies/nerfies.github.io">source
              code</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
